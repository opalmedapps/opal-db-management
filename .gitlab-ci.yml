# see: https://docs.gitlab.com/ee/ci/caching/#cache-python-dependencies
# Change pip's cache directory to be inside the project directory since we can
# only cache local items.
variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"

default:
  image: python:3.11.9-slim-bookworm

.default_before:
  before_script:
    - uname -a
    - python --version
    - which python
    # install dependencies for mysqlclient
    - apt update && apt-get install -y libmariadb-dev pkg-config
    # don't fail if venv is not set up yet (during setup)
    - python -m venv .venv
    - source .venv/bin/activate || true

stages:
  - build
  - static analysis
  - test

setup:
  stage: .pre
  extends: .default_before
  script:
    - python -m venv .venv
    - source .venv/bin/activate
    - pip install --upgrade pip
    - pip install -r requirements/development.txt
  artifacts:
    # pin artifacts to the branch
    # see: https://docs.gitlab.com/ee/ci/pipelines/job_artifacts.html#use-cicd-variables-to-define-the-artifacts-name
    name: $CI_COMMIT_REF_SLUG
    expire_in: 1 week
    paths:
      - .venv
  # Pip's cache doesn't store the python packages
  # https://pip.pypa.io/en/stable/reference/pip_install/#caching
  #
  # If you want to also cache the installed packages, you have to install
  # them in a virtualenv and cache it as well.
  cache:
    # pin artifacts to the branch
    # see: https://docs.gitlab.com/ee/ci/pipelines/job_artifacts.html#use-cicd-variables-to-define-the-artifacts-name
    paths:
      - .cache/pip

build alembic image:
  stage: build
  image: docker:26.1.2
  services:
    - docker:26.1.2-dind
  variables:
    # Use TLS https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#tls-enabled
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_CERTDIR: "/certs"
  before_script:
    # login to CI registry: https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#option-1-run-docker-login
    - echo $CI_REGISTRY_PASSWORD | docker login $CI_REGISTRY --username $CI_REGISTRY_USER --password-stdin
  script:
    - export IMAGE_REPOSITORY=$CI_REGISTRY_IMAGE/alembic
    # create an image tagged with the branch or tag name
    - export IMAGE_BRANCH=$IMAGE_REPOSITORY:$CI_COMMIT_REF_SLUG
    # plus for the default branch create a latest and commit tag
    # the commit tag allows us to get images of previous commits in case of problems
    - export IMAGE_LATEST=$IMAGE_REPOSITORY:latest
    - export IMAGE_COMMIT=$IMAGE_REPOSITORY:$CI_COMMIT_SHA
    # make use of the Docker cache to speed up building
    # see: https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#make-docker-in-docker-builds-faster-with-docker-layer-caching
    - docker pull $IMAGE_LATEST || true
    - docker pull $IMAGE_BRANCH || true
    - docker build --cache-from $IMAGE_BRANCH --cache-from $IMAGE_LATEST --tag $IMAGE_BRANCH --tag $IMAGE_LATEST --tag $IMAGE_COMMIT .
    - docker push $IMAGE_BRANCH
    - |
      if [[ "$CI_COMMIT_BRANCH" == "$CI_DEFAULT_BRANCH" ]]; then
        echo "Running on default branch. Pushing latest and commit tags..."
        docker push $IMAGE_LATEST
        docker push $IMAGE_COMMIT
      fi

flake8:
  stage: static analysis
  extends: .default_before
  needs:
    - setup
  script:
    - flake8 --version
    # install plugin to produce code climate report
    - pip install flake8-gl-codeclimate
    # don't fail if there are errors so the result can also be printed to the console for logs
    # fix relative file paths so GitLab is happy and shows the violations properly
    # see: https://github.com/awelzel/flake8-gl-codeclimate/issues/14
    - flake8 --format gl-codeclimate | python -c "import sys; import json; lines = [line.replace('./', '') for line in sys.stdin]; print(json.dumps(json.loads('\n'.join(lines)), indent='\t'));" > gl-code-quality-report.json || true
    # fail if JSON file does not contain empty array
    - cat gl-code-quality-report.json | grep -q "\[\]"
  artifacts:
    when: always
    reports:
      codequality: gl-code-quality-report.json

mypy:
  stage: static analysis
  extends: .default_before
  needs:
    - setup
  script:
    # install plugin to produce code climate report
    - pip install mypy-gitlab-code-quality
    - mypy --version
    # export output and don't fail if there are errors
    - mypy db_management/ --no-error-summary > mypy-out.txt || true
    - PYTHONHASHSEED=0 mypy-gitlab-code-quality < mypy-out.txt > codequality.json
     # fail if JSON file does not contain empty array
    - cat codequality.json | grep -q "\[\]"
  artifacts:
    when: always
    reports:
      codequality: codequality.json

markdownlint:
  stage: static analysis
  needs:
    - setup
  image:
    name: davidanson/markdownlint-cli2:v0.13.0
    # overwrite default entrypoint (which is a call to markdownlint-cli2)
    entrypoint: [""]
  before_script:
    - markdownlint-cli2 --version
  script:
    # use the config file that is stored outside the root
    - markdownlint-cli2 --config .gitlab/markdownlint/.markdownlint-cli2.yaml "**/*.md" "#.venv"
  artifacts:
    when: always
    reports:
      codequality: markdownlint-cli2-codequality.json


.database_service:
  needs:
    - job: setup
  extends: .default_before
  variables:
    MARIADB_ROOT_PASSWORD: $DB_ROOT_PASSWORD
    # ensure that user has permissions for test DB to be used by pytest
    MARIADB_DATABASE: OpalDB
    MARIADB_USER: citest
    MARIADB_PASSWORD: $DB_PASSWORD
  services:
    - mariadb:10.11.7-jammy
  script:
    # set up env file for DB service
    # use sample env file
    - cp .env.sample .env
    - sed -i "s/^DATABASE_ROOT_PASSWORD=.*/DATABASE_ROOT_PASSWORD=$DB_ROOT_PASSWORD/" .env
    - sed -i "s/^DATABASE_USER=.*/DATABASE_USER=$MARIADB_USER/" .env
    - sed -i "s/^DATABASE_PASSWORD=.*/DATABASE_PASSWORD=$DB_PASSWORD/" .env
    - sed -i "s/^DATABASE_HOST=.*/DATABASE_HOST=mariadb/" .env
    - cat .env
    # create additional DBs for legacy DB tests (OpalDB & QuestionnaireDB)
    - apt update && apt-get install -y default-mysql-client
    - MYSQL_PWD=$DB_ROOT_PASSWORD mysql -uroot -hmariadb -e "CREATE DATABASE IF NOT EXISTS \`QuestionnaireDB\` /*!40100 DEFAULT CHARACTER SET utf8 */; GRANT ALL PRIVILEGES ON \`QuestionnaireDB\`.* TO \`$MARIADB_USER\`@\`%\`;"
    - MYSQL_PWD=$DB_ROOT_PASSWORD mysql -uroot -hmariadb -e "CREATE DATABASE IF NOT EXISTS \`OrmsDatabase\` /*!40100 DEFAULT CHARACTER SET latin1 */; GRANT ALL PRIVILEGES ON \`OrmsDatabase\`.* TO \`$MARIADB_USER\`@\`%\`;"
    - MYSQL_PWD=$DB_ROOT_PASSWORD mysql -uroot -hmariadb -e "CREATE DATABASE IF NOT EXISTS \`OrmsLog\` /*!40100 DEFAULT CHARACTER SET latin1 */; GRANT ALL PRIVILEGES ON \`OrmsLog\`.* TO \`$MARIADB_USER\`@\`%\`;"


pytest:
  stage: test
  extends:
    - .database_service
  script:
    # see: https://docs.gitlab.com/ee/ci/yaml/yaml_optimization.html#reference-tags
    - !reference [.database_service, script]
    - pytest --version
    - pytest -v --junitxml=report.xml
  artifacts:
    when: always
    expire_in: "7 days"
    reports:
      junit: report.xml

run sql scripts:
  stage: test
  extends:
    - .database_service
  needs:
    # ensure the artifacts from setup are available
    - setup
    - pytest
  script:
    - !reference [.database_service, script]
    # migrate databases first
    - ./docker/alembic-upgrade.sh
    # Full refresh for both OMI and OHIGPH datasets to ensure no broken data links/inconsistencies
    - db_management/reset_data.sh OMI
    - db_management/reset_data.sh OHIGPH

# run pipelines for default branch, tags, and all types of merge request pipelines
# to support merge trains
# see: https://gitlab.com/gitlab-org/gitlab/-/issues/13159#note_373865588
include:
  # https://gitlab.com/gitlab-org/gitlab/-/blob/master/lib/gitlab/ci/templates/Workflows/MergeRequest-Pipelines.gitlab-ci.yml
  - template: 'Workflows/MergeRequest-Pipelines.gitlab-ci.yml'
  # use latest template versions to run security scanning jobs also in merge request pipelines:
  # https://docs.gitlab.com/ee/user/application_security/index.html#use-security-scanning-tools-with-merge-request-pipelines
  # Secret Detection: https://docs.gitlab.com/ee/user/application_security/secret_detection/
  # See: https://gitlab.com/gitlab-org/gitlab/-/blob/master/lib/gitlab/ci/templates/Jobs/Secret-Detection.latest.gitlab-ci.yml
  - template: Jobs/Secret-Detection.latest.gitlab-ci.yml
  # Dependency Scanning: https://docs.gitlab.com/ee/user/application_security/dependency_scanning/
  # https://gitlab.com/gitlab-org/gitlab/-/blob/master/lib/gitlab/ci/templates/Jobs/Dependency-Scanning.latest.gitlab-ci.yml
  - template: Jobs/Dependency-Scanning.latest.gitlab-ci.yml
  # Container Scanning: https://docs.gitlab.com/ee/user/application_security/container_scanning/
  # https://gitlab.com/gitlab-org/gitlab/-/blob/master/lib/gitlab/ci/templates/Jobs/Container-Scanning.latest.gitlab-ci.yml
  - template: Jobs/Container-Scanning.latest.gitlab-ci.yml
  # SAST Scanning: https://docs.gitlab.com/ee/user/application_security/sast/
  # https://gitlab.com/gitlab-org/gitlab/-/blob/master/lib/gitlab/ci/templates/Jobs/SAST.latest.gitlab-ci.yml
  - template: Jobs/SAST.latest.gitlab-ci.yml

# Customizations
#

# Secret Detection
# https://docs.gitlab.com/ee/user/application_security/secret_detection/#configure-scan-settings
secret_detection:
  # ignore artifacts from previous jobs, such as .venv directory
  dependencies: []

# Dependency Scanning
# https://docs.gitlab.com/ee/user/application_security/dependency_scanning/#customizing-analyzer-behavior
gemnasium-python-dependency_scanning:
  dependencies:
    - "setup"
  variables:
    # specifying this variable also prevents the "exists: **/requirements.txt" rule to be applied
    PIP_REQUIREMENTS_FILE: "development.txt"
  # the scanner actually installs the dependencies via pip and therefore requires the mysql client to be installed
  before_script:
    - apt update && apt install -y libmariadb-dev pkg-config

# Container Scanning
# https://docs.gitlab.com/ee/user/application_security/container_scanning/#customizing-the-container-scanning-settings
container_scanning:
  variables:
    CS_IMAGE: $CI_REGISTRY_IMAGE/alembic:$CI_COMMIT_REF_SLUG
